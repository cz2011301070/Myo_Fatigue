{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, pickle, time\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "%matplotlib inline\n",
    "from utils import *\n",
    "# %matplotlib qt\n",
    "import neurokit2 as nk\n",
    "from scipy.stats import entropy\n",
    "from scipy import stats\n",
    "from pyentrp import entropy as ent\n",
    "# from scipy.signal import welch, find_peaks, savgol_filter, butter_bandpass_filter\n",
    "from scipy.signal import welch, find_peaks, savgol_filter,butter\n",
    "import scipy.signal as signal\n",
    "from pyentrp import entropy as ent\n",
    "from scipy.stats import moment\n",
    "# from PyEMD import EMD\n",
    "import pywt\n",
    "import nolds\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "plt.rcParams['figure.figsize'] = (10,8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_emg_csv(parent_folder, folder, subfolder):\n",
    "    path = os.path.join(parent_folder, folder, \"Myo\", subfolder, \"EMG.csv\")\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path)\n",
    "        # markers = df[' Marker'].unique()\n",
    "        # # print(markers)\n",
    "        # # count = df[' Marker'].value_counts()\n",
    "        # # print(count)\n",
    "        data = {}\n",
    "        myo_elctrodes = [' Electrode 1', ' Electrode 2', ' Electrode 3',' Electrode 4', ' Electrode 5', ' Electrode 6', ' Electrode 7',' Electrode 8',]\n",
    "        for i , (dir, s,e) in enumerate(zip(['Y' , 'Z', 'X'],[1000, 2000, 3000], [1001, 2001, 3001])):\n",
    "            start_row_indices = df[df[' Marker'] == s].index\n",
    "            end_row_indices = df[df[' Marker'] == e].index\n",
    "            data[f'TskDir_{dir}'] = []\n",
    "            for start, end in zip(start_row_indices, end_row_indices):\n",
    "                data[f'TskDir_{dir}'].append(df.iloc[start + 1: end][myo_elctrodes].values)\n",
    "        # print(f\"Successfully read EMG.csv in {os.path.join(parent_folder, folder, 'Myo', subfolder)}\")\n",
    "        return data\n",
    "    else:\n",
    "        # print(f\"EMG.csv not found in {os.path.join(parent_folder, folder, 'Myo', subfolder)}\")\n",
    "        return None\n",
    "    \n",
    "parent_folder_path = './Experimental_Data'\n",
    "subfolder_names = [\"ControllerAndPen\", \"TwoControllers\", \"TwoHand\"]\n",
    "EMG_Dataset = {}\n",
    "for folder in os.listdir(parent_folder_path):\n",
    "    if os.path.isdir(os.path.join(parent_folder_path, folder)):\n",
    "        EMG_Dataset[f'{folder}'] = {}\n",
    "        for subfolder in subfolder_names:\n",
    "            EMG_Dataset[f'{folder}'][f'{subfolder}'] = read_emg_csv(parent_folder_path, folder, subfolder)\n",
    "            \n",
    "print(EMG_Dataset.keys())       \n",
    "print(EMG_Dataset['P01_Data'].keys())\n",
    "print(EMG_Dataset['P01_Data']['TwoControllers'].keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================================================================\n",
    "#                            [Band Pass Filter]\n",
    "#================================================================================\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = signal.lfilter(b, a, data)    # 这个y的格式和data的格式一样\n",
    "    return y\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5): # fs为采样频率\n",
    "    nyq = 0.5 * fs \n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='bandpass') # 分子b，分母a\n",
    "    return b, a\n",
    "\n",
    "\n",
    "#================================================================================\n",
    "#                            [Willison Amplitude]\n",
    "#================================================================================\n",
    "def cal_willison_amplitude(emg_data, threshold=0.1):\n",
    "    'emg shape: [pnts, channel]'\n",
    "    diff_data = np.diff(emg_data, axis=0)\n",
    "    wamp = np.sum(np.abs(diff_data) > threshold, axis=0)\n",
    "    return wamp\n",
    "\n",
    "#================================================================================\n",
    "#                            [Simple Square Integral]\n",
    "#================================================================================\n",
    "def cal_simple_square_integral(emg_data):\n",
    "    'emg shape: [pnts, channel]'\n",
    "    ssi = np.sum(emg_data**2, axis=0)\n",
    "    return ssi\n",
    "#================================================================================\n",
    "#                            [Integrated EMG]\n",
    "#================================================================================\n",
    "def cal_integrated_emg(emg_data):\n",
    "    'emg shape: [pnts, channel]'\n",
    "    iemg = np.sum(np.abs(emg_data), axis=0)\n",
    "    return iemg\n",
    "\n",
    "#================================================================================\n",
    "#                            [Mean Absolute Value]\n",
    "#================================================================================\n",
    "\n",
    "def cal_mav(emg_data):\n",
    "    'emg shape: [pnts, channel]'\n",
    "    mav = np.mean(np.abs(emg_data), axis=0)\n",
    "    return mav\n",
    "\n",
    "#================================================================================\n",
    "#                            [Root Mean Square]\n",
    "#================================================================================\n",
    "def cal_root_mean_square(emg_data):\n",
    "    'emg shape: [pnts, channel]'\n",
    "    rms = np.sqrt(np.mean(emg_data**2, axis=0))\n",
    "    return rms\n",
    "\n",
    "#================================================================================\n",
    "#                            [Median Frequency]\n",
    "#================================================================================\n",
    "def cal_median_frequency(emg_data, fs=200, nperseg=200):\n",
    "    'emg shape: [pnts, channel]'\n",
    "    mdf = []\n",
    "    for elec_idx in range(emg_data.shape[1]):\n",
    "        electrode_data = emg_data[:, elec_idx]\n",
    "        freqs, Pxx = welch(electrode_data, fs, nperseg=nperseg)\n",
    "        cumsum = np.cumsum(Pxx)\n",
    "        median_freq = freqs[np.where(cumsum >= cumsum[-1] / 2)[0][0]]\n",
    "        mdf.append(median_freq)\n",
    "    mdf = np.array(mdf)\n",
    "    return mdf\n",
    "\n",
    "#================================================================================\n",
    "#                            [Mean Frequency]\n",
    "#================================================================================\n",
    "def cal_mean_frequency(emg_data, fs=200, nperseg=200):\n",
    "    'emg shape: [pnts, channel]'\n",
    "    mnf = []\n",
    "    for elec_idx in range(emg_data.shape[1]):\n",
    "        f, Pxx = welch(emg_data[:, elec_idx], fs, nperseg=nperseg)\n",
    "        mnf.append(np.sum(f * Pxx) / np.sum(Pxx))\n",
    "    mnf = np.array(mnf)\n",
    "    return mnf\n",
    "\n",
    "#================================================================================\n",
    "#                            [Peak Frequency]\n",
    "#================================================================================\n",
    "def cal_peak_frequency(emg_data, fs=200, nperseg=200):\n",
    "    'emg shape: [pnts, channel]'\n",
    "    pkf = []\n",
    "    for ch_idx in range(emg_data.shape[1]):\n",
    "        f, Pxx = welch(emg_data[:, ch_idx], fs, nperseg=nperseg)\n",
    "        pkf.append(f[np.argmax(Pxx)])\n",
    "    pkf = np.array(pkf)\n",
    "    return pkf\n",
    "\n",
    "#================================================================================\n",
    "#                            [Mean Power]\n",
    "#================================================================================\n",
    "def cal_mean_power(emg_data, fs=200, nperseg =200):\n",
    "    mnp = []\n",
    "    for ch_idx in range(emg_data.shape[1]):\n",
    "        f, Pxx = welch(emg_data[:, ch_idx], fs, nperseg=nperseg)\n",
    "        mnp.append(np.mean(Pxx))\n",
    "    \n",
    "    mnp = np.array(mnp)\n",
    "    return mnp\n",
    "\n",
    "#================================================================================\n",
    "#                            [Total Power]\n",
    "#================================================================================\n",
    "def cal_total_power(emg_data, fs=200, nperseg=200):\n",
    "    ttp = []\n",
    "    for ch_idx in range(emg_data.shape[1]):\n",
    "        f, Pxx = welch(emg_data[:, ch_idx], fs, nperseg=nperseg)\n",
    "        ttp.append(np.sum(Pxx))\n",
    "    ttp = np.array(ttp)\n",
    "\n",
    "    return ttp\n",
    "\n",
    "#================================================================================\n",
    "#                            [Waveform Lenght]\n",
    "#================================================================================\n",
    "def cal_waveform_length(emg_data):\n",
    "    'emg shape: [pnts, channel]'\n",
    "    wl = np.sum(np.abs(np.diff(emg_data, axis=0)), axis=0)\n",
    "    return wl\n",
    "\n",
    "#================================================================================\n",
    "#                            [Sample Entropy]\n",
    "#================================================================================\n",
    "def cal_sample_entropy(emg_data, m=2, r=0.2):\n",
    "    'emg shape: [pnts, channel]'\n",
    "    sentropy = []\n",
    "    for elec_idx in range(emg_data.shape[1]):\n",
    "        se = ent.sample_entropy(emg_data[:, elec_idx], m, r)\n",
    "        sentropy.append(se[-1])  # Use the last value (m = 2)\n",
    "    return np.array(sentropy)\n",
    "\n",
    "#================================================================================\n",
    "#                            [Slop Sign Change]\n",
    "#================================================================================\n",
    "def cal_slope_sign_changes(emg_data):\n",
    "    'emg shape: [pnts, channel]'\n",
    "    diff_data = np.diff(emg_data, axis=0)\n",
    "    ssc = np.sum((diff_data[:-1, :] * diff_data[1:, :]) < 0, axis=0)\n",
    "    return ssc\n",
    "\n",
    "#================================================================================\n",
    "#                            [Zero Crossing Rate]\n",
    "#================================================================================\n",
    "def cal_zero_crossing_rate(emg_data):\n",
    "    'emg shape: [pnts, channel]'\n",
    "    zcr = np.sum((emg_data[:-1, :] * emg_data[1:, :]) < 0, axis=0)\n",
    "    return zcr\n",
    "\n",
    "#================================================================================\n",
    "#                            [Hjorth]\n",
    "#================================================================================\n",
    "def cal_hjorth_parameters(emg_data):\n",
    "    'emg shape: [pnts, channel]'\n",
    "    first_derivative = np.diff(emg_data, axis=0)\n",
    "    second_derivative = np.diff(first_derivative, axis=0)\n",
    "\n",
    "    activity = np.mean(emg_data**2, axis=0)\n",
    "    mobility = np.mean(first_derivative**2, axis=0) / activity\n",
    "    complexity = (np.mean(second_derivative**2, axis=0) / np.mean(first_derivative**2, axis=0)) / mobility\n",
    "\n",
    "    return activity, mobility, complexity\n",
    "\n",
    "#================================================================================\n",
    "#                            [Spectral Moments]\n",
    "#================================================================================\n",
    "def cal_spectral_moments(emg_data, fs=200, nperseg=200):\n",
    "    'emg shape: [pnts, channel]'\n",
    "    mean_frequency, variance_frequency  = [], []\n",
    "    \n",
    "    for elec_idx in range(emg_data.shape[1]):\n",
    "        f, Pxx = welch(emg_data[:, elec_idx], fs=fs, nperseg=nperseg)\n",
    "        mean_freq = np.sum(f * Pxx) / np.sum(Pxx)\n",
    "        mean_frequency.append(mean_freq)\n",
    "        variance_frequency.append(moment(Pxx, moment=2))\n",
    "        \n",
    "    mean_frequency = np.array(mean_frequency)\n",
    "    variance_frequency = np.array(variance_frequency)\n",
    "\n",
    "    return mean_frequency, variance_frequency\n",
    "\n",
    "#================================================================================\n",
    "#                            [Wavelet Transform]\n",
    "#================================================================================\n",
    "\n",
    "def cal_wavelet_transform(emg_data, wavelet='db4'):\n",
    "    'emg shape: [pnts, channel]'\n",
    "\n",
    "    wavelet_coeffs_list = pywt.wavedec(emg_data, wavelet, axis=0)\n",
    "\n",
    "    return wavelet_coeffs_list\n",
    "\n",
    "#================================================================================\n",
    "#                            [Deterended Fluctuations Analysis]\n",
    "#================================================================================\n",
    "\n",
    "def cal_detrended_fluctuation_analysis(emg_data):\n",
    "    'emg shape: [pnts, channel]'\n",
    "    dfa = []\n",
    "    for elec_idx in range(emg_data.shape[1]):\n",
    "        dfa.append(nolds.dfa(emg_data[:, elec_idx]))\n",
    "    return np.array(dfa)\n",
    "\n",
    "#================================================================================\n",
    "#                            [Windowing]\n",
    "#================================================================================\n",
    "\n",
    "def window_emg_data(emg_data, fs, window_length, overlap=0):\n",
    "    'emg shape: [pnts, channel]'\n",
    "    num_samples, num_electrodes = emg_data.shape\n",
    "    window_length = int(window_length*fs)\n",
    "    overlap = int(overlap * fs)\n",
    "    step_size = window_length - overlap\n",
    "    num_windows = (num_samples - overlap) // step_size\n",
    "\n",
    "    windowed_emg_data = np.empty((window_length, num_windows, num_electrodes))\n",
    "\n",
    "    for win_idx in range(num_windows):\n",
    "        start_sample = win_idx * step_size\n",
    "        end_sample = start_sample + window_length\n",
    "        windowed_emg_data[:, win_idx, :] = emg_data[start_sample:end_sample, :]\n",
    "    return windowed_emg_data\n",
    "\n",
    "#================================================================================\n",
    "#                            [Plot EMG]\n",
    "#================================================================================\n",
    "\n",
    "def plot_emg(data_list, fig_size=(12, 8), scale=1.01, ylim=None):\n",
    "    'data is a list of inputs with shape of [pnts, channel]'\n",
    "    \n",
    "    channel= data_list[0].shape[1]\n",
    "    channel_max = 0.0\n",
    "    fig, ax = plt.subplots(channel, 1, sharex=True, figsize=fig_size)\n",
    "    for i in range(channel):\n",
    "        for j in range(len(data_list)):\n",
    "            data = data_list[j]\n",
    "            ax[i].plot(data[:, i], linewidth=0.5)\n",
    "            if ylim is None:\n",
    "                channel_max_cur = np.max(np.abs(data[:,i])) * scale\n",
    "                if channel_max_cur>channel_max:\n",
    "                    channel_max = channel_max_cur\n",
    "                ax[i].set_ylim(-channel_max, channel_max)\n",
    "            else:\n",
    "                ax[i].set_ylim(ylim[0], ylim[1])\n",
    "            ax[i].set_ylabel(f'Channel {i+1}')\n",
    "            if i == channel-1:\n",
    "                ax[i].set_xlabel('Time')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "#================================================================================\n",
    "#                            [EMG Trend]\n",
    "#================================================================================ \n",
    "\n",
    "def channel_trend(data, fs=200, regressor='linear'):\n",
    "    'data shape: [pnts, channel]'\n",
    "    time = np.arange(0, len(data))\n",
    "    num_channels = data.shape[1]\n",
    "    \n",
    "    regression_models = []\n",
    "    for i in range(num_channels):\n",
    "        channel_data = data[:, i].reshape(-1, 1)\n",
    "        time_reshaped = time.reshape(-1, 1)\n",
    "        \n",
    "        if regressor=='linear':\n",
    "            # linear regressor\n",
    "            model = LinearRegression()\n",
    "            model.fit(time_reshaped, channel_data)\n",
    "            regression_models.append(model)\n",
    "            \n",
    "        elif regressor=='svr':\n",
    "            # Support vector regressor \n",
    "            model = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "            model.fit(time_reshaped, channel_data.ravel())\n",
    "            regression_models.append(model)\n",
    "            \n",
    "        elif regressor=='rf':\n",
    "            # RF regressor \n",
    "            model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "            model.fit(time_reshaped, channel_data.ravel())\n",
    "            regression_models.append(model)\n",
    "        else:\n",
    "            raise 'TypeError' \"current regressors are 'linear' | 'svr' | 'rf'\"\n",
    "\n",
    "    # Visualize the fitted regression curves\n",
    "    # fitted_curve = np.array([model.predict(time_reshaped).squeeze() for model in regression_models])\n",
    "    # plot_emg([data, fitted_curve.T])\n",
    "    if num_channels == 1:\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        axs = [ax]\n",
    "    else:\n",
    "        fig, axs = plt.subplots(num_channels, 1, figsize=(10, 5 * num_channels))\n",
    "    \n",
    "    # fig, axs = plt.subplots(num_channels, 1, figsize=(10, 5 * num_channels))\n",
    "    for i, model in enumerate(regression_models):\n",
    "        channel_data = data[:, i]\n",
    "        fitted_curve = model.predict(time_reshaped)\n",
    "\n",
    "        axs[i].plot(time, channel_data, label='EMG Channel {}'.format(i+1))\n",
    "        axs[i].plot(time, fitted_curve, label='Fitted Regression Curve', linestyle='--')\n",
    "        axs[i].set_xlabel('Time (s)')\n",
    "        axs[i].set_ylabel('Amplitude')\n",
    "        axs[i].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show() \n",
    "\n",
    "#================================================================================\n",
    "#                            [WCF Estimator]\n",
    "#================================================================================ \n",
    "def cal_wcf(emg_data_windows, window_func=np.hanning):\n",
    "    num_samples, num_windows, num_channels = emg_data_windows.shape\n",
    "    wcf = np.empty((num_windows, num_channels))\n",
    "\n",
    "    # calculate gamma for each channel\n",
    "    gamma = np.zeros(num_channels)\n",
    "    for channel in range(num_channels):\n",
    "        first_window_data = emg_data_windows[:, 0, channel] * window_func(num_samples)\n",
    "        first_window_fft = np.fft.fft(first_window_data)\n",
    "        gamma[channel] = np.sqrt(np.sum((num_samples - np.arange(1, num_samples)) *\n",
    "                                        (np.abs(first_window_fft[1:])**2)) / (num_samples - 1))\n",
    "\n",
    "        if gamma[channel] < 0.0001:\n",
    "            print(f'gamma too small for channel {channel+1}')\n",
    "\n",
    "    # calculate wcf for each window and channel\n",
    "    for channel in range(num_channels):\n",
    "        for window_id in range(num_windows):\n",
    "            window_data = emg_data_windows[:, window_id, channel]\n",
    "            # apply window function\n",
    "            windowed_data = window_data * window_func(num_samples)\n",
    "            # calculate fft\n",
    "            dft_window = np.fft.fft(windowed_data, axis=0)\n",
    "            dft_magnitude_squared = np.abs(dft_window[1:])**2\n",
    "            # calculate wcf \n",
    "            wcf_cur = np.sqrt(np.sum((num_samples - np.arange(1, num_samples)) * dft_magnitude_squared) / (num_samples - 1))\n",
    "            wcf[window_id, channel] = 2 * (window_id + 1) - (1 / gamma[channel]) * wcf_cur\n",
    "            \n",
    "    return wcf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "* Working On Specific Participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# participant here is \"P02_Data\"\n",
    "x = EMG_Dataset['P01_Data']['TwoControllers']['TskDir_Y'][4]    # ['ControllerAndPen', 'TwoControllers', 'TwoHand']\n",
    "# x_f = butter_bandpass_filter(x, fs=200, lowcut=20, highcut=90, axis=0)\n",
    "x_f = butter_bandpass_filter(x, fs=200, lowcut=20, highcut=90)\n",
    "x_rect = np.abs(x_f)\n",
    "# x_smooth = savgol_filter(x_rect, window_length=10, polyorder=2, axis=0, mode='interp')\n",
    "maximum_voluntary_contraction = np.max(x_rect, axis=0)\n",
    "x_norm = x_rect/maximum_voluntary_contraction\n",
    "plot_emg([x], fig_size=(12,10))\n",
    "\n",
    "x_win = window_emg_data(x_f, fs=200, window_length=0.15, overlap=0.075)\n",
    "\n",
    "print(f'data shape: {x.shape} | windowed: {x_win.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# participant here is \"P02_Data\"\n",
    "x = EMG_Dataset['zhuang.csv'][1]   # ['ControllerAndPen', 'TwoControllers', 'TwoHand']\n",
    "# x_f = butter_bandpass_filter(x, fs=200, lowcut=20, highcut=90, axis=0)\n",
    "x_f = butter_bandpass_filter(x, fs=200, lowcut=20, highcut=90)\n",
    "x_rect = np.abs(x_f)\n",
    "# x_smooth = savgol_filter(x_rect, window_length=10, polyorder=2, axis=0, mode='interp')\n",
    "maximum_voluntary_contraction = np.max(x_rect, axis=0)\n",
    "x_norm = x_rect/maximum_voluntary_contraction\n",
    "plot_emg([x], fig_size=(12,10))\n",
    "\n",
    "x_win = window_emg_data(x_f, fs=200, window_length=0.15, overlap=0.075)\n",
    "\n",
    "print(f'data shape: {x.shape} | windowed: {x_win.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track the fatigue based on features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features = []\n",
    "for i in range(x_win.shape[1]):\n",
    "    # x_features.append(cal_integrated_emg(x_win[:,i,:]))\n",
    "    # x_features.append(cal_willison_amplitude(x_win[:,i,:],threshold=0.1))\n",
    "    # x_features.append(cal_simple_square_integral(x_win[:,i,:]))\n",
    "    # x_features.append(cal_mav(x_win[:,i,:]))\n",
    "    # x_features.append(cal_mean_frequency(x_win[:,i,:], fs=200, nperseg=x_win.shape[0]))\n",
    "    x_features.append(cal_median_frequency(x_win[:,i,:], fs=200, nperseg=x_win.shape[0]))\n",
    "    # x_features.append(cal_root_mean_square(x_win[:,i,:]))\n",
    "    # x_features.append(cal_sample_entropy(x_win[:,i,:]))\n",
    "    # x_features.append(cal_slope_sign_changes(x_win[:,i,:]))\n",
    "    # x_features.append(cal_spectral_moments(x_win[:,i,:]))\n",
    "    # x_features.append(cal_zero_crossing_rate(x_win[:,i,:]))\n",
    "    # x_features.append(cal_waveform_length(x_win[:,i,:]))\n",
    "    \n",
    "x_features = np.array(x_features)\n",
    "print(x_features.shape)\n",
    "\n",
    "input = np.mean(x_features, axis=1, keepdims=True)\n",
    "input = x_features\n",
    "\n",
    "channel_trend(input, regressor='linear')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the most Important EMG Electrodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.99999999)\n",
    "pca.fit(x_features)\n",
    "\n",
    "explained_variance_ratios = pca.explained_variance_ratio_\n",
    "# print(\"Explained variance ratios: \", explained_variance_ratios)\n",
    "components = pca.components_\n",
    "print(len(components))\n",
    "most_important_channels = np.argmax(np.abs(components), axis=1) + 1\n",
    "# print(\"Most important channels for each principal component: \", most_important_channels)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bars = ax.bar(range(1, 8 + 1), explained_variance_ratios)\n",
    "ax.set_xlabel('Principal Components')\n",
    "ax.set_ylabel('Explained Variance Ratio')\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'Ch {most_important_channels[i]}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),  \n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WCF test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "# Iterate over subjects\n",
    "for subject, subject_data in EMG_Dataset.items():\n",
    "    # Iterate over objects\n",
    "    for object_name, object_data in subject_data.items():\n",
    "        # Iterate over directions\n",
    "        for direction, direction_data in object_data.items():\n",
    "            # Iterate over repetitions\n",
    "            for repetition in range(4):\n",
    "\n",
    "                # read data\n",
    "                x = EMG_Dataset[subject][object_name][direction][repetition]\n",
    "                # print(f'input data: {x.shape}')\n",
    "\n",
    "                # preprocessing\n",
    "                x_f = butter_bandpass_filter(x, fs=200, lowcut=20, highcut=90)\n",
    "                # x_rect = np.abs(x_f)\n",
    "                # x_smooth = savgol_filter(x_rect, window_length=10, polyorder=2, axis=0, mode='interp')\n",
    "                maximum_voluntary_contraction = np.max(x_f, axis=0)\n",
    "                x_norm = x_f/maximum_voluntary_contraction\n",
    "                x_p = x_norm        # change what kinf of data you want to use for process[raw | normalized| Rectified]\n",
    "                # print(x_p.shape)\n",
    "\n",
    "                # Windowing\n",
    "                win_len = 0.2\n",
    "                # print(f'max win_len is {x.shape[0]/200}')\n",
    "                overlap = 0.1\n",
    "                if win_len is None:\n",
    "                    x_win = x_p[:, None, :]\n",
    "                else:\n",
    "                    x_win = window_emg_data(x_p, fs=200, window_length=win_len, overlap=overlap)\n",
    "                # print(x_win.shape)\n",
    "\n",
    "                # Feature Extraction\n",
    "                # TODO: Replace RMS with WCF\n",
    "                x_feature = []\n",
    "                # for i in range (x_win.shape[2]):\n",
    "                #     # mav = cal_mav(x_win[:,i,:])\n",
    "                #     # mnf = cal_mean_frequency(x_win[:,i,:], fs=200, nperseg=x_win.shape[0])\n",
    "                #     # mdf = cal_median_frequency(x_win[:,i,:], fs=200, nperseg=x_win.shape[0])\n",
    "                #     # rms = cal_root_mean_square(x_win[:,i,:])\n",
    "                #     # print(f'x_win[:,:,i]: {x_win[:,:,i].shape}')\n",
    "                #     # print(f'x_win[:,i,:]: {x_win[:,i,:].shape}')\n",
    "                #     wcf = cal_wcf_single_channel(x_win[:,:,i], window_func=np.hanning) \n",
    "                    # print(f'wcf: {wcf.shape}')\n",
    "                    # x_feature.append(wcf)\n",
    "                \n",
    "                wcf = cal_wcf(x_win, window_func=np.hanning)\n",
    "                # print(f'wcf: {wcf.shape}')\n",
    "                # print(wcf)\n",
    "                x_feature.append(wcf)\n",
    "                # print(f'x_feature: {np.array(x_feature).shape}')\n",
    "\n",
    "                # regressor line slope inside each repeation\n",
    "                if x_win.shape[1]>1:\n",
    "                    # print('windowed features')\n",
    "                    # x_feature = regressor(np.array(x_feature), plot_trend=False)[None,:]\n",
    "                    x_feature = np.mean(np.array(x_feature), axis=0, keepdims=True)\n",
    "                    # x_feature = np.median(np.array(x_feature), axis=0, keepdims=True)\n",
    "                else:\n",
    "                    # print('non-windowed features')\n",
    "                    x_feature = np.array(x_feature)\n",
    "\n",
    "                # print(x_feature.shape)\n",
    "                x_feature_squeezed = np.squeeze(x_feature)\n",
    "                channels_data_lists = [x_feature_squeezed[:, channel].tolist() for channel in range(x_feature.shape[2])]\n",
    "\n",
    "                # for channel, channel_data_list in enumerate(channels_data_lists, start=1):\n",
    "                #     print(f\"Channel {channel} data:\", channel_data_list)\n",
    "\n",
    "                record = {\n",
    "                    'Subject': subject,\n",
    "                    'Object': object_name,\n",
    "                    'Direction': direction,\n",
    "                    'Repetition': repetition+1,\n",
    "                    'Channel1': channels_data_lists[0],\n",
    "                    'Channel2': channels_data_lists[1],\n",
    "                    'Channel3': channels_data_lists[2],\n",
    "                    'Channel4': channels_data_lists[3],\n",
    "                    'Channel5': channels_data_lists[4],\n",
    "                    'Channel6': channels_data_lists[5],\n",
    "                    'Channel7': channels_data_lists[6],\n",
    "                    'Channel8': channels_data_lists[7],\n",
    "                    'ChannelAvg': np.mean(x_feature_squeezed)\n",
    "                }\n",
    "                records.append(record)\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Paper Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# # Prepare the dataset (replace with your own data)\n",
    "# labels = np.array([...])  # Array of task labels (X, Y, Z) corresponding to each time point in the EMG data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(emg_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Train a RandomForest classifier\n",
    "# clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# # Predict and evaluate the classifier on the test set\n",
    "# y_pred = clf.predict(X_test)\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "# # Get feature importances for each channel\n",
    "# importances = clf.feature_importances_\n",
    "\n",
    "# # Print the feature importances\n",
    "# print(\"Feature importances: \", importances)\n",
    "\n",
    "# # You can also visualize the feature importances as a bar chart\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(range(1, num_channels + 1), importances)\n",
    "# ax.set_xlabel('Channels')\n",
    "# ax.set_ylabel('Feature Importance')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_participants = 10\n",
    "# num_repetitions = 10\n",
    "# num_tasks = 3\n",
    "# num_channels = 8\n",
    "# participant_rms = []\n",
    "# for i, (participant_key, participant_val) in enumerate(EMG_Dataset.items()):\n",
    "#     repetition_rms = []\n",
    "#     for repetition in range(10):\n",
    "#         task_rms = []\n",
    "#         emg_data_participant = participant_val['TwoHand']    # ['ControllerAndPen', 'TwoControllers', 'TwoHand']\n",
    "#         for dir_key, dir_val in emg_data_participant.items():\n",
    "            \n",
    "#             task_rms.append(cal_root_mean_square(dir_val[repetition]))\n",
    "            \n",
    "#         repetition_rms.append(np.array(task_rms))\n",
    "#     participant_rms.append(np.array(repetition_rms))\n",
    "# participant_rms = np.array(participant_rms)\n",
    "    \n",
    "\n",
    "# participants, repetitions, tasks, channels = np.meshgrid(range(num_participants), range(num_repetitions), range(num_tasks), range(num_channels), indexing='ij')\n",
    "# rms_values = np.moveaxis(participant_rms, -1, -2)\n",
    "# f_value, p_value = stats.f_oneway(*rms_values)\n",
    "\n",
    "# print(\"ANOVA results:\")\n",
    "# print(\"F-value:\", f_value)\n",
    "# print(\"P-value:\", p_value)\n",
    "# print(p_value.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import scipy.stats as stats\n",
    "\n",
    "# num_participants = 12\n",
    "# num_repetitions = 10\n",
    "\n",
    "# # Calculate the RMS values for each channel during each task for each participant and repetition\n",
    "# participant_rms = {}\n",
    "# for participant in range(num_participants):\n",
    "#     repetition_rms = {}\n",
    "#     for repetition in range(num_repetitions):\n",
    "#         task_rms = {}\n",
    "#         emg_data_participant = emg_data[participant]  # Replace with the appropriate indexing for your data\n",
    "#         for task, (start_time, end_time) in task_intervals.items():\n",
    "#             start_idx = int(start_time * fs)\n",
    "#             end_idx = int(end_time * fs)\n",
    "#             task_signal = emg_data_participant[start_idx:end_idx, :]\n",
    "#             task_rms[task] = compute_rms(task_signal)\n",
    "#         repetition_rms[repetition] = task_rms\n",
    "#     participant_rms[participant] = repetition_rms\n",
    "\n",
    "# # Perform a four-way ANOVA to compare the RMS values across participants, repetitions, channels, and tasks\n",
    "# participants, repetitions, tasks, channels = np.meshgrid(range(num_participants), range(num_repetitions), range(len(task_intervals)), range(num_channels), indexing='ij')\n",
    "# rms_values = np.array([[[[participant_rms[participant][repetition][task][channel] for channel in range(num_channels)] for task in task_intervals] for repetition in range(num_repetitions)] for participant in range(num_participants)])\n",
    "# f_value, p_value = stats.f_oneway(*rms_values.T)\n",
    "\n",
    "# print(\"ANOVA results:\")\n",
    "# print(\"F-value:\", f_value)\n",
    "# print(\"P-value:\", p_value)\n",
    "\n",
    "# # If the ANOVA test is significant, perform post-hoc tests (e.g., Tukey's HSD test)\n",
    "# alpha = 0.05\n",
    "# if p_value < alpha:\n",
    "#     from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "#     # Prepare the data for the Tukey's HSD test\n",
    "#     rms_values_flat = rms_values.flatten()\n",
    "#     participant_labels = np.repeat(participants.ravel(), len(task_intervals) * num_channels * num_repetitions)\n",
    "#     repetition_labels = np.tile(np.repeat(repetitions.ravel(), len(task_intervals) * num_channels), num_participants)\n",
    "#     channel_labels = np.tile(np.repeat(channels.ravel(), len(task_intervals)), num_participants * num_repetitions)\n",
    "#     task_labels = np.tile(tasks.ravel(), num_channels * num_participants * num_repetitions)\n",
    "\n",
    "#     # Perform the Tukey's HSD test\n",
    "#     tukey_results = pairwise_tukeyhsd(rms_values_flat, np.stack((participant_labels, repetition_labels, task_labels, channel_labels), axis=1))\n",
    "#     print(\"\\nTukey's HSD test results:\")\n",
    "#     print(tukey_results)\n",
    "# else:\n",
    "#     print(\"\\nNo significant difference between participants, repetitions, channels, and tasks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyer_notebook_projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
